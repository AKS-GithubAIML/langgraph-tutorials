{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fe01464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65bfc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5922b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    joke: str\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0561076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "\n",
    "    prompt = f'generate a joke on the topic {state[\"topic\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'joke': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95ff880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(state: JokeState):\n",
    "\n",
    "    prompt = f'write an explanation for the joke - {state[\"joke\"]}'\n",
    "    response = llm.invoke(prompt).content\n",
    "\n",
    "    return {'explanation': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1093470",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(JokeState)\n",
    "\n",
    "graph.add_node('generate_joke', generate_joke)\n",
    "graph.add_node('generate_explanation', generate_explanation)\n",
    "\n",
    "graph.add_edge(START, 'generate_joke')\n",
    "graph.add_edge('generate_joke', 'generate_explanation')\n",
    "graph.add_edge('generate_explanation', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8f11c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pizza',\n",
       " 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\",\n",
       " 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "workflow.invoke({'topic':'pizza'}, config=config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6857b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9eecda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-02-08T04:15:17.407589+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, tasks=(PregelTask(id='8dba37d4-cc6b-37de-3471-1928672094b4', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:15:14.740823+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, tasks=(PregelTask(id='d57d2309-d1d3-4341-6dce-081a86523484', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-02-08T04:15:14.739293+00:00', parent_config=None, tasks=(PregelTask(id='b7921a82-4522-7262-2500-72029cc406c7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "628a9f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'pasta',\n",
       " 'joke': 'Why did the pasta go to the party?\\n\\nBecause it heard it was going to be a saucy affair!',\n",
       " 'explanation': 'This joke plays on the double meaning of the word \"saucy.\" In one sense, \"saucy\" can refer to a lively or cheeky atmosphere at a party. In another sense, it refers to pasta being served with sauce. So, the joke is implying that the pasta went to the party because it heard there would be a lot of sauce (a saucy affair). It\\'s a playful and punny way of imagining pasta as a guest at a party.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "workflow.invoke({'topic':'pasta'}, config=config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef5beb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7d0ea21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-02-08T04:15:17.407589+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, tasks=(PregelTask(id='8dba37d4-cc6b-37de-3471-1928672094b4', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:15:14.740823+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, tasks=(PregelTask(id='d57d2309-d1d3-4341-6dce-081a86523484', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-02-08T04:15:14.739293+00:00', parent_config=None, tasks=(PregelTask(id='b7921a82-4522-7262-2500-72029cc406c7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fccccee",
   "metadata": {},
   "source": [
    "### Time Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5bfa235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7d2e73",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoint_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1f06cc6e-7232-6cb1-8000-f71609e6cec5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3016\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   3013\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3014\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3016\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3022\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3024\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3025\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2583\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2580\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2581\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2610\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2612\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/_loop.py:1039\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/_loop.py:666\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd55cf35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-02-08T04:15:17.407589+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, tasks=(PregelTask(id='8dba37d4-cc6b-37de-3471-1928672094b4', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:15:14.740823+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, tasks=(PregelTask(id='d57d2309-d1d3-4341-6dce-081a86523484', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-02-08T04:15:14.739293+00:00', parent_config=None, tasks=(PregelTask(id='b7921a82-4522-7262-2500-72029cc406c7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b895e",
   "metadata": {},
   "source": [
    "#### Updating State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19378d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f104a53-3af4-613a-8000-cebbedcc8a2e'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc6e-7232-6cb1-8000-f71609e6cec5\", \"checkpoint_ns\": \"\"}}, {'topic':'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c486bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a53-3af4-613a-8000-cebbedcc8a2e'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:18:20.843438+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, tasks=(PregelTask(id='795d9578-995c-7491-5c0e-21b0b6ca8ac6', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-02-08T04:15:17.407589+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, tasks=(PregelTask(id='8dba37d4-cc6b-37de-3471-1928672094b4', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:15:14.740823+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, tasks=(PregelTask(id='d57d2309-d1d3-4341-6dce-081a86523484', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-02-08T04:15:14.739293+00:00', parent_config=None, tasks=(PregelTask(id='b7921a82-4522-7262-2500-72029cc406c7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58f63a80",
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyInputError",
     "evalue": "Received no input for __start__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyInputError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcheckpoint_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m1f06cc72-ca16-6359-8001-7eea05e07dd2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:3016\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   3013\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3014\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3016\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3017\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3021\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3022\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3024\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3025\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3026\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3029\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3030\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/main.py:2583\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2580\u001b[39m runtime = parent_runtime.merge(runtime)\n\u001b[32m   2581\u001b[39m config[CONF][CONFIG_KEY_RUNTIME] = runtime\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSyncPregelLoop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2585\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStreamProtocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_modes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2586\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2587\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2588\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2592\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2593\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream_channels_asis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2596\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrigger_to_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmigrate_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_migrate_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2603\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2604\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# create runner\u001b[39;49;00m\n\u001b[32m   2605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPregelRunner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2606\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2607\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_RUNNER_SUBMIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWeakMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2610\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnode_finished\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCONF\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG_KEY_NODE_FINISHED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2611\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2612\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# enable subgraph streaming\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/_loop.py:1039\u001b[39m, in \u001b[36mSyncPregelLoop.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1037\u001b[39m \u001b[38;5;28mself\u001b[39m.stop = \u001b[38;5;28mself\u001b[39m.step + \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28mself\u001b[39m.checkpoint_previous_versions = \u001b[38;5;28mself\u001b[39m.checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m].copy()\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m \u001b[38;5;28mself\u001b[39m.updated_channels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/LangGraph/.venv/lib/python3.12/site-packages/langgraph/pregel/_loop.py:666\u001b[39m, in \u001b[36mPregelLoop._first\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m._put_checkpoint({\u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m CONFIG_KEY_RESUMING \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m configurable:\n\u001b[32m--> \u001b[39m\u001b[32m666\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyInputError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived no input for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    667\u001b[39m \u001b[38;5;66;03m# update config\u001b[39;00m\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_nested:\n",
      "\u001b[31mEmptyInputError\u001b[39m: Received no input for __start__"
     ]
    }
   ],
   "source": [
    "workflow.invoke(None, {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_id\": \"1f06cc72-ca16-6359-8001-7eea05e07dd2\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db645da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a53-3af4-613a-8000-cebbedcc8a2e'}}, metadata={'source': 'update', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:18:20.843438+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06cc6e-7232-6cb1-8000-f71609e6cec5'}}, tasks=(PregelTask(id='795d9578-995c-7491-5c0e-21b0b6ca8ac6', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\", 'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-75b1-6d06-8002-ee040767840c'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2026-02-08T04:15:19.098043+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza', 'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}, next=('generate_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-6592-6af6-8001-a67ede65925d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2026-02-08T04:15:17.407589+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, tasks=(PregelTask(id='8dba37d4-cc6b-37de-3471-1928672094b4', name='generate_explanation', path=('__pregel_pull', 'generate_explanation'), error=None, interrupts=(), state=None, result={'explanation': 'This joke plays on the idea that the pizza is experiencing emotional stress and pressure due to having too many toppings. By saying that the pizza went to a therapist, it suggests that the pizza is seeking help to deal with its problems. The humor comes from the unexpected image of a pizza seeking therapy and the play on words with the toppings causing pressure both physically and emotionally.'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c23-6ffc-8000-ab984278f613'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2026-02-08T04:15:14.740823+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, tasks=(PregelTask(id='d57d2309-d1d3-4341-6dce-081a86523484', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': \"Why did the pizza go to the therapist? Because it had too many toppings and couldn't handle the pressure!\"}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f104a4c-4c20-6460-bfff-bfaf0f029ecd'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2026-02-08T04:15:14.739293+00:00', parent_config=None, tasks=(PregelTask(id='b7921a82-4522-7262-2500-72029cc406c7', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8435127",
   "metadata": {},
   "source": [
    "### Fault Tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7aacf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import TypedDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095de12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the state\n",
    "class CrashState(TypedDict):\n",
    "    input: str\n",
    "    step1: str\n",
    "    step2: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13365a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define steps\n",
    "def step_1(state: CrashState) -> CrashState:\n",
    "    print(\" Step 1 executed\")\n",
    "    return {\"step1\": \"done\", \"input\": state[\"input\"]}\n",
    "\n",
    "def step_2(state: CrashState) -> CrashState:\n",
    "    print(\" Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\")\n",
    "    time.sleep(1000)  # Simulate long-running hang\n",
    "    return {\"step2\": \"done\"}\n",
    "\n",
    "def step_3(state: CrashState) -> CrashState:\n",
    "    print(\" Step 3 executed\")\n",
    "    return {\"done\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2838a3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build the graph\n",
    "builder = StateGraph(CrashState)\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "builder.set_entry_point(\"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c012e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running graph: Please manually interrupt during Step 2...\n",
      " Step 1 executed\n",
      " Step 2 hanging... now manually interrupt from the notebook toolbar (STOP button)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\" Running graph: Please manually interrupt during Step 2...\")\n",
    "    graph.invoke({\"input\": \"start\"}, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "except KeyboardInterrupt:\n",
    "    print(\" Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df3f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Re-run to show fault-tolerant resume\n",
    "print(\"\\n Re-running the graph to demonstrate fault tolerance...\")\n",
    "final_state = graph.invoke(None, config={\"configurable\": {\"thread_id\": 'thread-1'}})\n",
    "print(\"\\n Final State:\", final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f61ccbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph.get_state_history({\"configurable\": {\"thread_id\": 'thread-1'}}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
